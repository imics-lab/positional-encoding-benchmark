{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Lk1ZflFddtU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class FixedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(FixedPositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class LearnedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(LearnedPositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.pe = nn.Parameter(torch.randn(max_len, d_model))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "def get_pos_encoder(pos_encoding):\n",
        "    if pos_encoding == 'fixed':\n",
        "        return FixedPositionalEncoding\n",
        "    elif pos_encoding == 'learned':\n",
        "        return LearnedPositionalEncoding\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown positional encoding type: {pos_encoding}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoderLayer\n",
        "\n",
        "class TSTransformerEncoder(nn.Module):\n",
        "    def __init__(self, feat_dim, max_len, d_model, n_heads, num_layers, dim_feedforward, dropout=0.1,\n",
        "                 pos_encoding='fixed', activation='gelu', norm='BatchNorm', freeze=False):\n",
        "        super(TSTransformerEncoder, self).__init__()\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.project_inp = nn.Linear(feat_dim, d_model)\n",
        "        self.pos_enc = get_pos_encoder(pos_encoding)(d_model, dropout=dropout*(1.0 - freeze), max_len=max_len)\n",
        "\n",
        "        if norm == 'LayerNorm':\n",
        "            encoder_layer = TransformerEncoderLayer(d_model, self.n_heads, dim_feedforward, dropout*(1.0 - freeze), activation=activation)\n",
        "        else:\n",
        "            encoder_layer = TransformerBatchNormEncoderLayer(d_model, self.n_heads, dim_feedforward, dropout*(1.0 - freeze), activation=activation)\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "\n",
        "        self.output_layer = nn.Linear(d_model, feat_dim)\n",
        "\n",
        "        self.act = _get_activation_fn(activation)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.feat_dim = feat_dim\n",
        "\n",
        "    def forward(self, X, padding_masks):\n",
        "        inp = X.permute(1, 0, 2)\n",
        "        inp = self.project_inp(inp) * math.sqrt(self.d_model)\n",
        "        inp = self.pos_enc(inp)\n",
        "        output = self.transformer_encoder(inp, src_key_padding_mask=~padding_masks)\n",
        "        output = self.act(output)\n",
        "        output = output.permute(1, 0, 2)\n",
        "        output = self.dropout1(output)\n",
        "        output = self.output_layer(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def _get_activation_fn(activation):\n",
        "    if activation == \"relu\":\n",
        "        return F.relu\n",
        "    elif activation == \"gelu\":\n",
        "        return F.gelu\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid activation function: {activation}\")\n",
        "\n",
        "class TransformerBatchNormEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"gelu\"):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.norm1 = nn.BatchNorm1d(d_model)\n",
        "        self.norm2 = nn.BatchNorm1d(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = _get_activation_fn(activation)\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "        src2 = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = src.transpose(0, 1).transpose(1, 2)\n",
        "        src = self.norm1(src)\n",
        "        src = src.transpose(1, 2).transpose(0, 1)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = src.transpose(0, 1).transpose(1, 2)\n",
        "        src = self.norm2(src)\n",
        "        src = src.transpose(1, 2).transpose(0, 1)\n",
        "        return src\n"
      ],
      "metadata": {
        "id": "aA3QkkFtdrrQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torch.nn import TransformerEncoderLayer\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Positional Encodings\n",
        "class FixedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(FixedPositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class LearnedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(LearnedPositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.pe = nn.Parameter(torch.randn(1, max_len, d_model))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "def get_pos_encoder(pos_encoding):\n",
        "    if pos_encoding == 'fixed':\n",
        "        return FixedPositionalEncoding\n",
        "    elif pos_encoding == 'learned':\n",
        "        return LearnedPositionalEncoding\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown positional encoding type: {pos_encoding}\")\n",
        "\n",
        "# Activation Function\n",
        "def _get_activation_fn(activation):\n",
        "    if activation == \"relu\":\n",
        "        return F.relu\n",
        "    elif activation == \"gelu\":\n",
        "        return F.gelu\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid activation function: {activation}\")\n",
        "\n",
        "# Custom Transformer Encoder Layer with Batch Normalization\n",
        "class TransformerBatchNormEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"gelu\"):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.norm1 = nn.BatchNorm1d(d_model)\n",
        "        self.norm2 = nn.BatchNorm1d(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = _get_activation_fn(activation)\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None, **kwargs):\n",
        "        src2 = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = src.transpose(0, 1).transpose(1, 2)\n",
        "        src = self.norm1(src)\n",
        "        src = src.transpose(1, 2).transpose(0, 1)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = src.transpose(0, 1).transpose(1, 2)\n",
        "        src = self.norm2(src)\n",
        "        src = src.transpose(1, 2).transpose(0, 1)\n",
        "        return src\n",
        "\n",
        "# Main Transformer Encoder Model\n",
        "class TSTransformerEncoder(nn.Module):\n",
        "    def __init__(self, feat_dim, max_len, d_model, n_heads, num_layers, dim_feedforward, dropout=0.1,\n",
        "                 pos_encoding='fixed', activation='gelu', norm='BatchNorm', freeze=False):\n",
        "        super(TSTransformerEncoder, self).__init__()\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.project_inp = nn.Linear(feat_dim, d_model)\n",
        "        self.pos_enc = get_pos_encoder(pos_encoding)(d_model, dropout=dropout*(1.0 - freeze), max_len=max_len)\n",
        "\n",
        "        if norm == 'LayerNorm':\n",
        "            encoder_layer = TransformerEncoderLayer(d_model, self.n_heads, dim_feedforward, dropout*(1.0 - freeze), activation=activation)\n",
        "        else:\n",
        "            encoder_layer = TransformerBatchNormEncoderLayer(d_model, self.n_heads, dim_feedforward, dropout*(1.0 - freeze), activation=activation)\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "\n",
        "        self.output_layer = nn.Linear(d_model, feat_dim)\n",
        "\n",
        "        self.act = _get_activation_fn(activation)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.feat_dim = feat_dim\n",
        "\n",
        "    def forward(self, X, padding_masks):\n",
        "        inp = X.permute(1, 0, 2)\n",
        "        inp = self.project_inp(inp) * math.sqrt(self.d_model)\n",
        "        inp = self.pos_enc(inp)\n",
        "        output = self.transformer_encoder(inp, src_key_padding_mask=~padding_masks)\n",
        "        output = self.act(output)\n",
        "        output = output.permute(1, 0, 2)\n",
        "        output = self.dropout1(output)\n",
        "        output = self.output_layer(output)\n",
        "        return output\n",
        "\n",
        "# Generate Dummy Data\n",
        "def generate_dummy_data(num_samples, seq_length, feat_dim):\n",
        "    X = np.random.randn(num_samples, seq_length, feat_dim)\n",
        "    y = np.random.randint(0, 2, size=(num_samples, seq_length))  # Ensure y has the same sequence length\n",
        "    return X, y\n",
        "\n",
        "# Split Data\n",
        "X, y = generate_dummy_data(1000, 50, 32)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Training Function\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            padding_masks = (inputs != 0).any(dim=-1)\n",
        "            outputs = model(inputs, padding_masks)\n",
        "            outputs = outputs.view(-1, model.feat_dim)  # Flatten output to (batch_size * seq_length, feat_dim)\n",
        "            labels = labels.view(-1)  # Flatten labels to (batch_size * seq_length)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            padding_masks = (inputs != 0).any(dim=-1)\n",
        "            outputs = model(inputs, padding_masks)\n",
        "            outputs = outputs.view(-1, model.feat_dim)  # Flatten output to (batch_size * seq_length, feat_dim)\n",
        "            labels = labels.view(-1)  # Flatten labels to (batch_size * seq_length)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "    accuracy = correct / (len(val_loader.dataset) * val_loader.dataset.tensors[0].shape[1])\n",
        "    return total_loss / len(val_loader), accuracy\n",
        "\n",
        "# Initialize and Train Models with Different Positional Encodings\n",
        "models = {\n",
        "    'fixed': TSTransformerEncoder(feat_dim=32, max_len=50, d_model=128, n_heads=8, num_layers=6, dim_feedforward=512, pos_encoding='fixed'),\n",
        "    'learned': TSTransformerEncoder(feat_dim=32, max_len=50, d_model=128, n_heads=8, num_layers=6, dim_feedforward=512, pos_encoding='learned'),\n",
        "}\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
        "    val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
        "    results[name] = {'val_loss': val_loss, 'val_accuracy': val_accuracy}\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvyu43MGeOZb",
        "outputId": "293f240a-c261-4d13-e09b-6e247e42a9ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fixed': {'val_loss': 2.1011813708714078, 'val_accuracy': 0.4996}, 'learned': {'val_loss': 1.8620926312037878, 'val_accuracy': 0.5039}}\n"
          ]
        }
      ]
    }
  ]
}